---
# yaml-language-server: $schema=https://kubernetes-schemas.pages.dev/helm.toolkit.fluxcd.io/helmrelease_v2.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: kube-prometheus-stack
  namespace: kube-prometheus-stack
spec:
  interval: 15m
  chart:
    spec:
      chart: kube-prometheus-stack
      version: 79.8.1
      sourceRef:
        kind: HelmRepository
        name: prometheus-community
        namespace: flux-system
      interval: 15m
  timeout: 20m
  maxHistory: 3
  install:
    createNamespace: true
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    crds:
      enabled: true
      upgradeJob:
        enabled: true
        forceConflicts: true
    defaultRules:
      create: true
      rules:
        alertmanager: false # unlikely errors in 1 replica setup
        etcd: false
        general: false # no watchdog/scrape failure IDEALLY SET THIS UP
        k8s: true
        k8sContainerMemorySwap: false # dropped container_memory_swap
        k8sContainerMemoryCache: true # used in node compute dashboard
        k8sPodOwner: true # used in good dashboards
        kubeApiserver: false
        kubeApiserverAvailability: false
        kubeApiserverError: false
        kubeApiserverSlos: false
        kubeControllerManager: false
        kubelet: false # dumb pleg rules
        kubePrometheusGeneral: false # not using up1 / up0 anyway
        kubePrometheusNodeRecording: false # for node overview dashboards
        kubernetesApps: true
        kubernetesResources: false # don't care about quotas atm
        kubernetesStorage: false # pvc warnings are good, but local-provisioner do not support them yet
        kubernetesSystem: false
        kubeScheduler: false
        kubeSchedulerAlerting: false
        kubeStateMetrics: true
        network: false # don't care bout network flaps atm
        node: false # don't need these to visualise them - default boards are bad
        nodeExporterAlerting: false
        nodeExporterRecording: false
        prometheus: true # nice safety
        prometheusOperator: true # nice safety when not using admission webhook
        windows: false # wat
      disabled:
        # some of the heavier prom alerts that we don't need
        PrometheusNotIngestingSamples: true
        PrometheusRemoteStorageFailures: true
        PrometheusRemoteWriteDesiredShards: true
        PrometheusRemoteWriteBehind: true
    cleanPrometheusOperatorObjectNames: true
    prometheusOperator:
      enabled: true
      kubeletService:
        enabled: enabled
        namespace: kube-system
      serviceMonitor:
        selfMonitor: true
        metricRelabelings:
        # we can look at this if things start to fail don't need histograms
        - sourceLabels: [__name__]
          regex: 'prometheus_operator_(kubernetes_client|reconcile_duration).*'
          action: drop
        # we are not debugging go services
        - sourceLabels: [__name__]
          regex: 'go_sched_.*_bucket'
          action: drop
      revisionHistoryLimit: 4
    windowsMonitoring:
      enabled: false
    prometheus-windows-exporter:
      prometheus:
        monitor:
          enabled: false
    nodeExporter:
      enabled: true
      jobLabel: job
      operatingSystems:
        darwin:
          enabled: false
    prometheus-node-exporter:
      fullnameOverride: node-exporter
      podLabels:
        job: node-exporter
      prometheus:
        monitor:
          relabelings:
            - action: replace
              regex: (.*)
              replacement: $1
              sourceLabels: ["__meta_kubernetes_pod_node_name"]
              targetLabel: kubernetes_node
          metricRelabelings:
            # we are not debugging go services
            - sourceLabels: [__name__]
              regex: '^go_.*'
              action: drop
  ## Configuration for kube-state-metrics subchart
    kube-state-metrics:
      prometheus:
        monitor:
          enabled: true
          metricRelabelings:
          # Drop less useful pod metrics (5x per pod..)
          - sourceLabels: [__name__]
            regex: 'kube_pod_status_reason'
            action: drop
          - sourceLabels: [__name__]
            regex: 'kube_pod_tolerations|kube_pod_status_qos_class|kube_pod_scheduler|kube_pod_service_account|kube_pod_status_scheduled_time'
            action: drop
          - sourceLabels: [__name__]
            regex: 'kube_replicaset_(status|spec|metadata|created).*'
            action: drop

    grafana:
      enabled: false
      forceDeployDashboards: true
      defaultDashboardsEnabled: true
      serviceMonitor:
        enabled: true
        metricRelabelings:
        - sourceLabels: [__name__]
          regex: '(grafana_http_|grafana_live_|grafana_frontend_|grafana_access|grafana_alerting|grafan_folder|grafana_plugin|grafana_feature_toggles).*'
          action: drop
        - sourceLabels: [__name__]
          regex: 'grafana.*_bucket'
          action: drop
        - sourceLabels: [__name__]
          action: drop
          regex: '^go_.*'
      datasource:
        enabled: true
        default: true
        httpMethod: "POST"
        scrapeInterval: "30s"
        uid: "prometheus"
    kubeApiServer:
      enabled: false
      serviceMonitor:
        enabled: false
    kubelet:
      enabled: true
      serviceMonitor:
        # we want cadvisor (cpu/memory) metrics only
        probes: false
        cAdvisor: true
    coreDns:
      enabled: false
    kubeDns:
      enabled: false
    kubeEtcd:
      service:
        selector:
          component: kube-apiserver # etcd runs on control plane nodes
    kubeProxy:
      enabled: false
    kubeScheduler:
      enabled: false
    kubeControllerManager:
      enabled: false
    prometheus:
      ingress:
        enabled: true
        ingressClassName: traefik
        annotations:
          cert-manager.io/cluster-issuer: domain-0-le-prod
          cert-manager.io/private-key-rotation-policy: Always
          traefik.ingress.kubernetes.io/router.entrypoints: websecure
          traefik.ingress.kubernetes.io/router.tls: "true"
          traefik.ingress.kubernetes.io/router.middlewares: traefik-chain-basic@kubernetescrd
        hosts:
          - prom.${DOMAIN_0}
        paths:
          - /
        pathType: Prefix
        tls:
          - hosts:
            - prom.${DOMAIN_0}
            secretName: prometheus-tls-0
      serviceMonitor:
        metricRelabelings:
        - sourceLabels: [__name__]
          regex: 'prometheus_http_(request|response).*'
          action: drop
        - sourceLabels: [__name__]
          regex: 'prometheus_tsdb_(compaction_chunk|compaction_duration).*'
          action: drop
        - sourceLabels: [__name__]
          regex: '(net_conntrack).*'
          action: drop
        - sourceLabels: [__name__]
          regex: 'prometheus_sd_(consul|azure|kuma|nomad|linode).*'
          action: drop
        - sourceLabels: [__name__]
          action: drop
          regex: '^go_.*'
      portName: main
      prometheusSpec:
        enableAPIServer: false
        serviceMonitorSelectorNilUsesHelmValues: false
        scrapeConfigSelectorNilUsesHelmValues: false
        probeSelectorNilUsesHelmValues: false
        podMonitorSelectorNilUsesHelmValues: false
        ruleSelectorNilUsesHelmValues: false
        prometheusExternalLabelNameClear: true
        replicaExternalLabelNameClear: true
        enableAdminAPI: true
        walCompression: true
        enableFeatures:
          - memory-snapshot-on-shutdown
        retention: 7d
        retentionSize: 50GB
        resources:
          requests:
            cpu: 100m
          limits:
            memory: 2000Mi
    serviceMonitor:
      enabled: false
